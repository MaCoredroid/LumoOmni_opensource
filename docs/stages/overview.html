<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>LumoOmni Program Overview</title>
  <link rel="preconnect" href="https://fonts.googleapis.com" />
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
  <link href="https://fonts.googleapis.com/css2?family=Space+Grotesk:wght@400;500;600;700&family=Source+Serif+4:wght@300;400;500;600&display=swap" rel="stylesheet" />
  <link rel="stylesheet" href="../assets/style.css" />
</head>
<body>
  <div class="site">
    <nav class="nav">
      <div class="brand">
        <div class="brand-mark"></div>
        <div>
          <div>LumoOmni</div>
          <div style="font-size:11px; letter-spacing:0.18em; color:var(--ink-2)">Program Overview</div>
        </div>
      </div>
      <div class="nav-links">
        <a href="../index.html">Home</a>
        <a href="stage1.html">Stages</a>
        <a href="reports.html">Reports</a>
        <a href="resources.html">Resources</a>
      </div>
    </nav>

    <section class="section">
      <div class="kicker">Executive Summary</div>
      <h1 class="section-title">A staged roadmap for discrete-token multimodal modeling</h1>
      <p>
        LumoOmni organizes research into explicit stages with verification gates. The program
        begins with a Qwen3â€‘8B + SigLIP vision-language baseline (resampler/projector), moves into
        a Unified Token Interface built on SEED + EnCodec, and formalizes tokenized WebDataset
        pipelines anchored by token_space hashing. Each stage defines goals, deliverables, and
        failure modes so the system can scale to discrete-token multimodal generation.
      </p>
      <div class="card-grid" style="margin-top:24px;">
        <div class="card">
          <h3>Stage 1</h3>
          <p>Vision-language alignment with a connector-only training setup.</p>
          <a href="stage1.html">Read Stage 1</a>
        </div>
        <div class="card">
          <h3>Stage 1.1</h3>
          <p>Eval hardening, token-weighted loss, and golden set monitoring.</p>
          <a href="stage1-1.html">Read Stage 1.1</a>
        </div>
        <div class="card">
          <h3>Stage 2</h3>
          <p>Normalized data and deterministic tokenized shards.</p>
          <a href="stage2.html">Read Stage 2</a>
        </div>
        <div class="card">
          <h3>Stage 3.1</h3>
          <p>Unified Token Interface verification and audit tooling.</p>
          <a href="stage3-1.html">Read Stage 3.1</a>
        </div>
        <div class="card">
          <h3>Stage 3.2</h3>
          <p>Tokenized dataset verification and regression gating.</p>
          <a href="stage3-2.html">Read Stage 3.2</a>
        </div>
        <div class="card">
          <h3>Stage 3.3</h3>
          <p>Warm-start token LM and modality-robust training loops.</p>
          <a href="stage3-3.html">Read Stage 3.3</a>
        </div>
        <div class="card">
          <h3>Stage 3.4</h3>
          <p>Feedback cycles, decode compliance, and open gaps.</p>
          <a href="stage3-4.html">Read Stage 3.4</a>
        </div>
      </div>
    </section>

    <footer class="footer">
      <div class="kicker">Audience Fit</div>
      <p>Researchers get reproducible specs and audits. HR teams get a clear scope of impact and rigor.</p>
    </footer>
  </div>
  <script src="../assets/site.js"></script>
</body>
</html>
